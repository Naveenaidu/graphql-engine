{-|
= Scheduled Triggers

This module implements the functionality of invoking webhooks during specified
time events aka scheduled events. The scheduled events are the events generated
by the graphql-engine using the cron triggers or/and a scheduled event can
be created by the user at a specified time with the payload, webhook, headers
and the retry configuration. Scheduled events are modeled using rows in Postgres
with a @timestamp@ column.

This module implements scheduling and delivery of scheduled
events:

1. Scheduling a cron event involves creating new cron events. New
cron events are created based on the cron schedule and the number of
scheduled events that are already present in the scheduled events buffer.
The graphql-engine computes the new scheduled events and writes them to
the database.(Generator)

2. Delivering a scheduled event involves reading undelivered scheduled events
from the database and delivering them to the webhook server. (Processor)

The rationale behind separating the event scheduling and event delivery
mechanism into two different threads is that the scheduling and delivering of
the scheduled events are not directly dependent on each other. The generator
will almost always try to create scheduled events which are supposed to be
delivered in the future (timestamp > current_timestamp) and the processor
will fetch scheduled events of the past (timestamp < current_timestamp). So,
the set of the scheduled events generated by the generator and the processor
will never be the same. The point here is that they're not correlated to each
other. They can be split into different threads for a better performance.

== Implementation

During the startup, two threads are started:

1. Generator: Fetches the list of scheduled triggers from cache and generates
   the scheduled events.

    - Additional events will be generated only if there are fewer than 100
      scheduled events.

    - The upcoming events timestamp will be generated using:

        - cron schedule of the scheduled trigger

        - max timestamp of the scheduled events that already exist or
          current_timestamp(when no scheduled events exist)

        - The timestamp of the scheduled events is stored with timezone because
          `SELECT NOW()` returns timestamp with timezone, so it's good to
          compare two things of the same type.

    This effectively corresponds to doing an INSERT with values containing
    specific timestamp.

2. Processor: Fetches the undelivered cron events and the scheduled events
   from the database and which have timestamp lesser than the
   current timestamp and then process them.
-}
module Hasura.Eventing.ScheduledTrigger
  ( runCronEventsGenerator
  , processScheduledTriggers

  , CronEventSeed(..)
  , ScheduledEventType(..)
  , generateScheduleTimes
  -- , insertCronEvents
  , initLockedEventsCtx
  , LockedEventsCtx(..)
  -- , unlockScheduledEvents
  -- , unlockOneOffScheduledEvents
  -- , unlockAllLockedScheduledEvents

  -- , MonadMetadataStorageTx(..)
  ) where

import           Control.Arrow.Extended                 (dup)
import           Control.Concurrent.Extended            (sleep)
import           Control.Concurrent.STM.TVar
import           Data.Has
import           Data.List                              (unfoldr)
import           Data.Time.Clock
import           Hasura.Class
import           Hasura.Eventing.Common
import           Hasura.Eventing.HTTP
import           Hasura.Eventing.ScheduledTrigger.Types
import           Hasura.HTTP
import           Hasura.Prelude
import           Hasura.RQL.DDL.EventTrigger            (getHeaderInfosFromConf)
import           Hasura.RQL.DDL.Headers
import           Hasura.RQL.Types
import           Hasura.Server.Version                  (HasVersion)
import           System.Cron

import qualified Data.Aeson                             as J
import qualified Data.ByteString.Lazy                   as BL
import qualified Data.Environment                       as Env
import qualified Data.HashMap.Strict                    as Map
import qualified Data.Set                               as Set
import qualified Data.TByteString                       as TBS
import qualified Data.Text                              as T
import qualified Database.PG.Query                      as Q
import qualified Hasura.Logging                         as L
import qualified Hasura.Tracing                         as Tracing
import qualified Network.HTTP.Client                    as HTTP


-- | runCronEventsGenerator makes sure that all the cron triggers
--   have an adequate buffer of cron events.
runCronEventsGenerator
  :: ( MonadIO m
     , MonadMetadataStorageTx m
     )
  => L.Logger L.Hasura
  -> Q.PGPool
  -> IO SchemaCache
  -> m void
runCronEventsGenerator logger pgpool getSC = do
  forever $ do
    sc <- liftIO getSC
    -- get cron triggers from cache
    let cronTriggersCache = scCronTriggers sc

    -- get cron trigger stats from db
    deprivedCronTriggerStatsTx <- getDeprivedCronTriggerStatsTx
    insertCronEventsTx <- getInsertCronEventsTx
    (liftIO . runExceptT)
      (Q.runTx pgpool (Q.ReadCommitted, Just Q.ReadOnly) deprivedCronTriggerStatsTx) >>= \case
      Left err -> L.unLogger logger $
        ScheduledTriggerInternalErr $ err500 Unexpected (T.pack $ show err)
      Right deprivedCronTriggerStats -> do
        -- join stats with cron triggers and produce @[(CronTriggerInfo, CronTriggerStats)]@
        cronTriggersForHydrationWithStats <-
          catMaybes <$>
          mapM (withCronTrigger cronTriggersCache) deprivedCronTriggerStats
        -- insert cron events for cron triggers that need hydration
        (liftIO . runExceptT)
          (Q.runTx pgpool (Q.ReadCommitted, Just Q.ReadWrite) $
          insertCronEventsFor insertCronEventsTx cronTriggersForHydrationWithStats) >>= \case
          Right _ -> pure ()
          Left err ->
            L.unLogger logger $ ScheduledTriggerInternalErr $ err500 Unexpected (T.pack $ show err)
    liftIO $ sleep (minutes 1)
    where
      withCronTrigger cronTriggerCache cronTriggerStat = do
        case Map.lookup (ctsName cronTriggerStat) cronTriggerCache of
          Nothing -> do
            L.unLogger logger $
              ScheduledTriggerInternalErr $
                err500 Unexpected $
                "could not find scheduled trigger in the schema cache"
            pure Nothing
          Just cronTrigger -> pure $
            Just (cronTrigger, cronTriggerStat)

insertCronEventsFor
  :: InsertCronEventsTx
  -> [(CronTriggerInfo, CronTriggerStats)]
  -> Q.TxE QErr ()
insertCronEventsFor insertCronEvents' cronTriggersWithStats = do
  let scheduledEvents = flip concatMap cronTriggersWithStats $ \(cti, stats) ->
        generateCronEventsFrom (ctsMaxScheduledTime stats) cti
  case scheduledEvents of
    []     -> pure ()
    events -> insertCronEvents' events

generateCronEventsFrom :: UTCTime -> CronTriggerInfo-> [CronEventSeed]
generateCronEventsFrom startTime CronTriggerInfo{..} =
  map (CronEventSeed ctiName) $
      generateScheduleTimes startTime 100 ctiSchedule -- generate next 100 events

-- | Generates next @n events starting @from according to 'CronSchedule'
generateScheduleTimes :: UTCTime -> Int -> CronSchedule -> [UTCTime]
generateScheduleTimes from n cron = take n $ go from
  where
    go = unfoldr (fmap dup . nextMatch cron)

processCronEvents
  :: ( HasVersion
     , MonadIO m
     , Tracing.HasReporter m
     , MonadMetadataStorageTx m
     )
  => L.Logger L.Hasura
  -> LogEnvHeaders
  -> HTTP.Manager
  -> Q.PGPool
  -> IO SchemaCache
  -> TVar (Set.Set CronEventId)
  -> m ()
processCronEvents logger logEnv httpMgr pgpool getSC lockedCronEvents = do
  cronTriggersInfo <- scCronTriggers <$> liftIO getSC
  partialCronEventsTx <- getPartialCronEventsTx
  cronScheduledEvents <-
    liftIO . runExceptT $
      Q.runTx pgpool (Q.ReadCommitted, Just Q.ReadWrite) partialCronEventsTx
  case cronScheduledEvents of
    Right partialEvents -> do
      -- save the locked cron events that have been fetched from the
      -- database, the events stored here will be unlocked in case a
      -- graceful shutdown is initiated in midst of processing these events
      saveLockedEvents (map cepId partialEvents) lockedCronEvents
      -- The `createdAt` of a cron event is the `created_at` of the cron trigger
      for_ partialEvents $ \(CronEventPartial id' name st tries createdAt)-> do
        case Map.lookup name cronTriggersInfo of
          Nothing ->  logInternalError $
            err500 Unexpected "could not find cron trigger in cache"
          Just CronTriggerInfo{..} -> do
            let webhook = unResolvedWebhook ctiWebhookInfo
                payload' = fromMaybe J.Null ctiPayload
                scheduledEvent =
                    ScheduledEventFull id'
                                       (Just name)
                                       st
                                       tries
                                       webhook
                                       payload'
                                       ctiRetryConf
                                       ctiHeaders
                                       ctiComment
                                       createdAt
            finally <- runExceptT $
              runReaderT (processScheduledEvent logEnv pgpool scheduledEvent Cron) (logger, httpMgr)
            removeEventFromLockedEvents id' lockedCronEvents
            either logInternalError pure finally
    Left err -> logInternalError err
  where
    logInternalError err = liftIO . L.unLogger logger $ ScheduledTriggerInternalErr err

processOneOffScheduledEvents
  :: ( HasVersion
     , MonadIO m
     , Tracing.HasReporter m
     , MonadMetadataStorageTx m
     )
  => Env.Environment
  -> L.Logger L.Hasura
  -> LogEnvHeaders
  -> HTTP.Manager
  -> Q.PGPool
  -> TVar (Set.Set OneOffScheduledEventId)
  -> m ()
processOneOffScheduledEvents env logger logEnv httpMgr pgpool lockedOneOffScheduledEvents = do
  oneOffScheduledEventsTx <- getOneOffScheduledEventsTx
  oneOffScheduledEvents <-
    liftIO . runExceptT $
      Q.runTx pgpool (Q.ReadCommitted, Just Q.ReadWrite) oneOffScheduledEventsTx
  case oneOffScheduledEvents of
    Right oneOffScheduledEvents' -> do
      -- save the locked one-off events that have been fetched from the
      -- database, the events stored here will be unlocked in case a
      -- graceful shutdown is initiated in midst of processing these events
      saveLockedEvents (map ooseId oneOffScheduledEvents') lockedOneOffScheduledEvents
      for_ oneOffScheduledEvents' $
             \(OneOffScheduledEvent id'
                                    scheduledTime
                                    tries
                                    webhookConf
                                    payload
                                    retryConf
                                    headerConf
                                    comment
                                    createdAt)
        -> do
        webhookInfo <- liftIO . runExceptT $ resolveWebhook env webhookConf
        headerInfo <- liftIO . runExceptT $ getHeaderInfosFromConf env headerConf

        case webhookInfo of
          Right webhookInfo' -> do
            case headerInfo of
              Right headerInfo' -> do
                let webhook = unResolvedWebhook webhookInfo'
                    payload' = fromMaybe J.Null payload
                    scheduledEvent = ScheduledEventFull id'
                                                        Nothing
                                                        scheduledTime
                                                        tries
                                                        webhook
                                                        payload'
                                                        retryConf
                                                        headerInfo'
                                                        comment
                                                        createdAt
                finally <- runExceptT $
                  runReaderT (processScheduledEvent logEnv pgpool scheduledEvent OneOff) $
                    (logger, httpMgr)
                removeEventFromLockedEvents id' lockedOneOffScheduledEvents
                either logInternalError pure finally

              Left headerInfoErr -> logInternalError headerInfoErr

          Left webhookInfoErr -> logInternalError webhookInfoErr

    Left oneOffScheduledEventsErr -> logInternalError oneOffScheduledEventsErr
  where
    logInternalError err = liftIO . L.unLogger logger $ ScheduledTriggerInternalErr err

processScheduledTriggers
  :: ( HasVersion
     , MonadIO m
     , Tracing.HasReporter m
     , MonadMetadataStorageTx m
     )
  => Env.Environment
  -> L.Logger L.Hasura
  -> LogEnvHeaders
  -> HTTP.Manager
  -> Q.PGPool
  -> IO SchemaCache
  -> LockedEventsCtx
  -> m void
processScheduledTriggers env logger logEnv httpMgr pgpool getSC LockedEventsCtx {..} =
  forever $ do
    processCronEvents logger logEnv httpMgr pgpool getSC leCronEvents
    processOneOffScheduledEvents env logger logEnv httpMgr pgpool leOneOffEvents
    liftIO $ sleep (minutes 1)

processScheduledEvent
  :: ( MonadReader r m
     , Has HTTP.Manager r
     , Has (L.Logger L.Hasura) r
     , HasVersion
     , MonadIO m
     , MonadError QErr m
     , Tracing.HasReporter m
     , MonadMetadataStorageTx m
     )
  => LogEnvHeaders
  -> Q.PGPool
  -> ScheduledEventFull
  -> ScheduledEventType
  -> m ()
processScheduledEvent logEnv pgpool se@ScheduledEventFull {..} type' = Tracing.runTraceT traceNote do
  currentTime <- liftIO getCurrentTime
  if convertDuration (diffUTCTime currentTime sefScheduledTime)
    > unNonNegativeDiffTime (strcToleranceSeconds sefRetryConf)
    then processDead pgpool se type'
    else do
      let timeoutSeconds = round $ unNonNegativeDiffTime
                             $ strcTimeoutSeconds sefRetryConf
          httpTimeout = HTTP.responseTimeoutMicro (timeoutSeconds * 1000000)
          headers = addDefaultHeaders $ map encodeHeader sefHeaders
          extraLogCtx = ExtraLogContext (Just currentTime) sefId
          -- include `created_at` in the payload, only in one-off events
          createdAt = bool Nothing (Just sefCreatedAt) $ type' == OneOff
          webhookReqPayload =
            ScheduledEventWebhookPayload
              sefId sefName sefScheduledTime sefPayload sefComment createdAt
          webhookReqBodyJson = J.toJSON webhookReqPayload
          webhookReqBody = J.encode webhookReqBodyJson
          requestDetails = RequestDetails $ BL.length webhookReqBody
      res <- runExceptT $ tryWebhook headers httpTimeout webhookReqBody (T.unpack sefWebhook)
      logHTTPForST res extraLogCtx requestDetails
      let decodedHeaders = map (decodeHeader logEnv sefHeaders) headers
      either
        (processError pgpool se decodedHeaders type' webhookReqBodyJson)
        (processSuccess pgpool se decodedHeaders type' webhookReqBodyJson)
        res
  where
    traceNote = "Scheduled trigger" <> foldMap ((": " <>) . unNonEmptyText . unTriggerName) sefName

processError
  :: ( MonadIO m
     , MonadError QErr m
     , MonadMetadataStorageTx m
     )
  => Q.PGPool
  -> ScheduledEventFull
  -> [HeaderConf]
  -> ScheduledEventType
  -> J.Value
  -> HTTPErr a
  -> m ()
processError pgpool se decodedHeaders type' reqJson err = do
  let invocation = case err of
        HClient excp -> do
          let errMsg = TBS.fromLBS $ J.encode $ show excp
          mkInvocation se 1000 decodedHeaders errMsg [] reqJson
        HParse _ detail -> do
          let errMsg = TBS.fromLBS $ J.encode detail
          mkInvocation se 1001 decodedHeaders errMsg [] reqJson
        HStatus errResp -> do
          let respPayload = hrsBody errResp
              respHeaders = hrsHeaders errResp
              respStatus = hrsStatus errResp
          mkInvocation se respStatus decodedHeaders respPayload respHeaders reqJson
        HOther detail -> do
          let errMsg = (TBS.fromLBS $ J.encode detail)
          mkInvocation se 500 decodedHeaders errMsg [] reqJson
  insertInvocationTx <- getInsertInvocationTx
  retryOrMarkErrorTx <- retryOrMarkError se err type'
  liftExceptTIO $
    Q.runTx pgpool (Q.RepeatableRead, Just Q.ReadWrite) $ do
    insertInvocationTx invocation type'
    retryOrMarkErrorTx

retryOrMarkError
  :: (MonadIO m, MonadMetadataStorageTx m)
  => ScheduledEventFull -> HTTPErr a -> ScheduledEventType -> m (Q.TxE QErr ())
retryOrMarkError se@ScheduledEventFull {..} err type' = do
  let mRetryHeader = getRetryAfterHeaderFromHTTPErr err
      mRetryHeaderSeconds = parseRetryHeaderValue =<< mRetryHeader
      triesExhausted = sefTries >= strcNumRetries sefRetryConf
      noRetryHeader = isNothing mRetryHeaderSeconds
  if triesExhausted && noRetryHeader
    then do
      setScheduledEventStatusTx <- getSetScheduledEventStatusTx
      pure $ setScheduledEventStatusTx sefId SESError type'
    else do
      currentTime <- liftIO getCurrentTime
      let delay = fromMaybe (round $ unNonNegativeDiffTime
                             $ strcRetryIntervalSeconds sefRetryConf)
                    $ mRetryHeaderSeconds
          diff = fromIntegral delay
          retryTime = addUTCTime diff currentTime
      setRetryTx <- getSetRetryTx
      pure $ setRetryTx se retryTime type'

{- Note [Scheduled event lifecycle]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Scheduled events move between six different states over the course of their
lifetime, as represented by the following flowchart:
  ┌───────────┐      ┌────────┐      ┌───────────┐
  │ scheduled │─(a)─→│ locked │─(b)─→│ delivered │
  └───────────┘      └────────┘      └───────────┘
          ↑              │           ┌───────┐
          └────(c)───────┼─────(d)──→│ error │
                         │           └───────┘
                         │           ┌──────┐
                         └─────(e)──→│ dead │
                                     └──────┘

When a scheduled event is first created, it starts in the 'scheduled' state,
and it can transition to other states in the following ways:
  a. When graphql-engine fetches a scheduled event from the database to process
     it, it sets its state to 'locked'. This prevents multiple graphql-engine
     instances running on the same database from processing the same
     scheduled event concurrently.
  b. When a scheduled event is processed successfully, it is marked 'delivered'.
  c. If a scheduled event fails to be processed, but it hasn’t yet reached
     its maximum retry limit, its retry counter is incremented and
     it is returned to the 'scheduled' state.
  d. If a scheduled event fails to be processed and *has* reached its
     retry limit, its state is set to 'error'.
  e. If for whatever reason the difference between the current time and the
     scheduled time is greater than the tolerance of the scheduled event, it
     will not be processed and its state will be set to 'dead'.
-}

processSuccess
  :: (MonadIO m, MonadError QErr m, MonadMetadataStorageTx m)
  => Q.PGPool
  -> ScheduledEventFull
  -> [HeaderConf]
  -> ScheduledEventType
  -> J.Value
  -> HTTPResp a
  -> m ()
processSuccess pgpool se decodedHeaders type' reqBodyJson resp = do
  let respBody = hrsBody resp
      respHeaders = hrsHeaders resp
      respStatus = hrsStatus resp
      invocation = mkInvocation se respStatus decodedHeaders respBody respHeaders reqBodyJson
  insertInvocationTx <- getInsertInvocationTx
  setScheduledEventStatusTx <- getSetScheduledEventStatusTx
  liftExceptTIO $
    Q.runTx pgpool (Q.RepeatableRead, Just Q.ReadWrite) $ do
    insertInvocationTx invocation type'
    setScheduledEventStatusTx (sefId se) SESDelivered type'

processDead
  :: (MonadIO m, MonadError QErr m, MonadMetadataStorageTx m)
  => Q.PGPool -> ScheduledEventFull -> ScheduledEventType -> m ()
processDead pgpool se type' = do
  setScheduledEventStatus <- getSetScheduledEventStatusTx
  liftExceptTIO $
   Q.runTx pgpool (Q.RepeatableRead, Just Q.ReadWrite) $
     setScheduledEventStatus (sefId se) SESDead type'

mkInvocation
  :: ScheduledEventFull
  -> Int
  -> [HeaderConf]
  -> TBS.TByteString
  -> [HeaderConf]
  -> J.Value
  -> (Invocation 'ScheduledType)
mkInvocation ScheduledEventFull {sefId} status reqHeaders respBody respHeaders reqBodyJson
  = let resp = if isClientError status
          then mkClientErr respBody
          else mkResp status respBody respHeaders
    in
      Invocation
      sefId
      status
      (mkWebhookReq reqBodyJson reqHeaders invocationVersionST)
      resp

liftExceptTIO :: (MonadError e m, MonadIO m) => ExceptT e IO a -> m a
liftExceptTIO m = liftEither =<< liftIO (runExceptT m)
